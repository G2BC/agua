{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importação da bibs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import datetime\n",
    "from collections import defaultdict\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "\n",
    "date = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para remover duplicatas e salvar o arquivo final\n",
    "def remove_duplicates(input_file, output_file, lineage):\n",
    "    # Input\n",
    "    input_obj = open(input_file, 'r')\n",
    "\n",
    "    # Output\n",
    "    output_obj = open(output_file, 'w')\n",
    "\n",
    "    # Print info\n",
    "    print(\"[Input file]\\t: \" + input_obj.name)\n",
    "    print(\"[Output file]\\t: \" + output_obj.name)\n",
    "    print(\"[Lineage]\\t: \" + lineage)\n",
    "\n",
    "    # Dictionary to store unique sequences by their sequence string\n",
    "    uniq_seqs = {}\n",
    "\n",
    "    # Iterate through input sequences\n",
    "    for qry in SeqIO.parse(input_obj, 'fasta'):\n",
    "        seq_str = str(qry.seq)\n",
    "\n",
    "        # Check if this sequence string has been seen before\n",
    "        if seq_str not in uniq_seqs:\n",
    "            # If it's a new sequence string, save it\n",
    "            uniq_seqs[seq_str] = qry\n",
    "\n",
    "    # Making unique sequences\n",
    "    final_seq = list(uniq_seqs.values())\n",
    "\n",
    "    # Write output file\n",
    "    output_num = SeqIO.write(final_seq, output_obj, 'fasta')\n",
    "\n",
    "    # Close objects\n",
    "    input_obj.close()\n",
    "    output_obj.close()\n",
    "\n",
    "    # Sequence counts\n",
    "    input_num = 0\n",
    "    for input_seqs in open(input_file, 'r'):\n",
    "        if input_seqs.startswith(\">\"):\n",
    "            input_num += 1\n",
    "\n",
    "    # Number of duplicate sequences\n",
    "    Duplicate_num = input_num - output_num\n",
    "\n",
    "    # Print stats\n",
    "    print(\"[Input seq]\\t:\", input_num)\n",
    "    print(\"[Output seq]\\t:\", output_num)\n",
    "    print(\"[Duplicates]\\t:\", Duplicate_num)\n",
    "    print(\"[Lineage]\\t:\", lineage)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Program]\t: Filtra Sequências Únicas\n",
      "[Date]\t\t: 2023-10-11 11:31:15\n",
      "Analisando sequências em B.1.1.529\n",
      "[Input file]\t: /home/m_souza/tcc/dataset/new_dataset_vagner/B.1.1.529/sequencias_spike_filtradas.fasta\n",
      "[Output file]\t: /home/m_souza/tcc/dataset/new_dataset_vagner/B.1.1.529/sequencias_spike_final.fasta\n",
      "[Lineage]\t: B.1.1.529\n",
      "[Input seq]\t: 3122\n",
      "[Output seq]\t: 1937\n",
      "[Duplicates]\t: 1185\n",
      "[Lineage]\t: B.1.1.529\n",
      "Analisando sequências em B.1.1.7\n",
      "[Input file]\t: /home/m_souza/tcc/dataset/new_dataset_vagner/B.1.1.7/sequencias_spike_filtradas.fasta\n",
      "[Output file]\t: /home/m_souza/tcc/dataset/new_dataset_vagner/B.1.1.7/sequencias_spike_final.fasta\n",
      "[Lineage]\t: B.1.1.7\n",
      "[Input seq]\t: 6716\n",
      "[Output seq]\t: 1924\n",
      "[Duplicates]\t: 4792\n",
      "[Lineage]\t: B.1.1.7\n",
      "Analisando sequências em B.1.617.2\n",
      "[Input file]\t: /home/m_souza/tcc/dataset/new_dataset_vagner/B.1.617.2/sequencias_spike_filtradas.fasta\n",
      "[Output file]\t: /home/m_souza/tcc/dataset/new_dataset_vagner/B.1.617.2/sequencias_spike_final.fasta\n",
      "[Lineage]\t: B.1.617.2\n",
      "[Input seq]\t: 7079\n",
      "[Output seq]\t: 2243\n",
      "[Duplicates]\t: 4836\n",
      "[Lineage]\t: B.1.617.2\n",
      "Analisando sequências em P.1\n",
      "[Input file]\t: /home/m_souza/tcc/dataset/new_dataset_vagner/P.1/sequencias_spike_filtradas.fasta\n",
      "[Output file]\t: /home/m_souza/tcc/dataset/new_dataset_vagner/P.1/sequencias_spike_final.fasta\n",
      "[Lineage]\t: P.1\n",
      "[Input seq]\t: 8220\n",
      "[Output seq]\t: 2004\n",
      "[Duplicates]\t: 6216\n",
      "[Lineage]\t: P.1\n",
      "Analisando sequências em B.1.351\n",
      "[Input file]\t: /home/m_souza/tcc/dataset/new_dataset_vagner/B.1.351/sequencias_spike_filtradas.fasta\n",
      "[Output file]\t: /home/m_souza/tcc/dataset/new_dataset_vagner/B.1.351/sequencias_spike_final.fasta\n",
      "[Lineage]\t: B.1.351\n",
      "[Input seq]\t: 2107\n",
      "[Output seq]\t: 781\n",
      "[Duplicates]\t: 1326\n",
      "[Lineage]\t: B.1.351\n",
      "Concluído!\n"
     ]
    }
   ],
   "source": [
    "# Diretório principal onde você possui várias pastas\n",
    "diretorio_principal = '/home/m_souza/tcc/dataset/new_dataset_vagner'\n",
    "\n",
    "print(\"[Program]\\t: Filtra Sequências Únicas\")\n",
    "print(\"[Date]\\t\\t: \" + date.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "# Iterar sobre as pastas no diretório principal\n",
    "for pasta in os.listdir(diretorio_principal):\n",
    "    pasta_path = os.path.join(diretorio_principal, pasta)\n",
    "\n",
    "    # Verificar se é um diretório\n",
    "    if os.path.isdir(pasta_path):\n",
    "        # Procurar pelo arquivo sequencias_cortadas.fasta na pasta\n",
    "        arquivo_sequencias = os.path.join(pasta_path, 'sequencias_spike_filtradas.fasta')\n",
    "        path_sequencias_filtradas = os.path.join(pasta_path, 'sequencias_spike_final.fasta')\n",
    "\n",
    "        # Verificar se o arquivo existe\n",
    "        if os.path.exists(arquivo_sequencias):\n",
    "            print(f'Analisando sequências em {pasta}')\n",
    "\n",
    "            # Chamar a função para remover duplicatas e salvar o arquivo final\n",
    "            remove_duplicates(arquivo_sequencias, path_sequencias_filtradas, pasta)\n",
    "\n",
    "print('Concluído!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".bioEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
